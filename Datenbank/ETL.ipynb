{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/DMA2023TeamC/blob/main/Datenbank/ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDF6jnIrk5L8"
      },
      "source": [
        "# **Objective**: Create a Datawarehouse and transform data from source database to datawarehouse db\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFINDtv7IOsW"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reset -f"
      ],
      "metadata": {
        "id": "N10vKMnpz8Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAtASFg0NjWe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from sqlite3 import Error\n",
        "import random\n",
        "import string\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5SVaUDA3QRc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Mount google Drive to access the data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "print(f'The current working directory is:')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO-KOV0IITRx"
      },
      "source": [
        "# Path of input/output data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbN89u5p-vgO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define the variables to store the paths to csv files and to the data folder\n",
        "\n",
        "disease = 'metabolic_syndrome_disease'\n",
        "path_csv_files = f\"/content/drive/Shareddrives/TeamC/Material/csv_data/{disease}\"\n",
        "path_teamc = \"content/drive/Shareddrives/TeamC\"\n",
        "\n",
        "# path of the source database\n",
        "DB_SOURCE_PATH = \"/content/drive/Shareddrives/TeamC/teamc_db.db\"\n",
        "\n",
        "# path of the data warehouse\n",
        "DB_DWH_PATH = \"/content/drive/Shareddrives/TeamC/teamc_dwh.db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzL1jGs-751J",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define the patient type\n",
        "patient_type = \"metabolic_syndrome_disease\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_WekES-IlMO"
      },
      "source": [
        "# Create Datawarehouse "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SL03VkYnodn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class DB(object):\n",
        "  def __init__(self, db_file):\n",
        "    self.conn = sqlite3.connect(db_file)\n",
        "    self.cur = self.conn.cursor()\n",
        "    self.__init_db()\n",
        "  \n",
        "  # This function commits the changes and closes the connection\n",
        "  def __del__(self):\n",
        "      self.conn.commit()\n",
        "      self.conn.close()\n",
        "\n",
        "  # If the DB does not exist, it will be created. Afterwards empty tables will be created using the SQL Statements from the source DB\n",
        "  def __init_db(self):\n",
        "\n",
        "    # drop the existing tables (in case the code has been run already)\n",
        "    drop_patients_info = \"\"\"DROP TABLE IF EXISTS patients_info\"\"\"\n",
        "    drop_conditions_info = \"\"\"DROP TABLE IF EXISTS conditions_info\"\"\"\n",
        "    drop_medications_info = \"\"\"DROP TABLE IF EXISTS medications_info\"\"\"\n",
        "    drop_med_codes = \"\"\"DROP TABLE IF EXISTS med_codes\"\"\"\n",
        "    drop_conditions_codes = \"\"\"DROP TABLE IF EXISTS conditions_codes\"\"\"\n",
        "\n",
        "    #  sql query to create patients_info table\n",
        "    create_patients_info = \"\"\"CREATE TABLE IF NOT EXISTS patients_info (\n",
        "                            Id STRING PRIMARY KEY, \n",
        "                            BIRTHDATE DATE, \n",
        "                            DEATHDATE DATE,\n",
        "                            RACE STRING,\n",
        "                            ETHNICITY STRING\n",
        "                            );\"\"\"\n",
        "\n",
        "\n",
        "    # sql query to create conditions table\n",
        "    create_conditions_info = \"\"\"CREATE TABLE IF NOT EXISTS conditions_info (\n",
        "                                START DATE,\n",
        "                                STOP DATE, \n",
        "                                PATIENT STRING,\n",
        "                                CODE STRING,\n",
        "                                FOREIGN KEY (PATIENT) REFERENCES patients_info (Id)\n",
        "                                FOREIGN KEY (CODE) REFERENCES conditions_codes (CODE)\n",
        "                                );\"\"\"\n",
        "\n",
        "    # sql query to create medications table\n",
        "    create_medications_info = '''CREATE TABLE IF NOT EXISTS medications_info (\n",
        "                                  START DATE,\n",
        "                                  STOP DATE,\n",
        "                                  PATIENT STRING,\n",
        "                                  CODE STRING,\n",
        "                                  FOREIGN KEY (PATIENT) REFERENCES patients (Id)\n",
        "                                  FOREIGN KEY (CODE) REFERENCES med_codes (CODE)\n",
        "                                  );'''\n",
        "    # create table to store the medication codes and their description\n",
        "    create_med_codes = '''CREATE TABLE IF NOT EXISTS med_codes (\n",
        "                          CODE STRING,\n",
        "                          DESCRIPTION STRING);'''\n",
        "                          \n",
        "    # create table to store conditions codes and their description\n",
        "    create_conditions_codes = '''CREATE TABLE IF NOT EXISTS conditions_codes (\n",
        "                              CODE STRING,\n",
        "                              DESCRIPTION STRING);'''                   \n",
        "\n",
        "\n",
        "    # A list with the names of the tables that were created in the new DB\n",
        "    create_tables = [create_patients_info, # demographic data\n",
        "                     create_conditions_info, # diagnoses data\n",
        "                     create_medications_info,# encounters data\n",
        "                     create_med_codes, # medication codes and their description\n",
        "                     create_conditions_codes #condition codes and their description\n",
        "                     ]\n",
        "    drop_tables =  [drop_patients_info,\n",
        "                   drop_conditions_info,\n",
        "                   drop_medications_info,\n",
        "                   drop_med_codes,\n",
        "                   drop_conditions_codes]\n",
        "\n",
        "    if self.conn is not None: # If connection was succesfully initialized, the following loop will run\n",
        "      \n",
        "      # Drop every table\n",
        "      for query in drop_tables:\n",
        "        self.cur.execute(query)\n",
        "        \n",
        "      # For every element in the 'create_tables' list, its corresponding statement will be executed, \n",
        "      # which in this case means, the creating of the tables\n",
        "      for query in create_tables:\n",
        "        self.cur.execute(query)\n",
        "\n",
        "    else:\n",
        "      # If the connection was not succesfully initialized, print this message\n",
        "      print('Connection to database failed')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUIHYzr2IxMl"
      },
      "source": [
        "#ETL/ELT (Extract, transform, load )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBMOAjmPReGG",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Defining class SqlQuery and its methods\n",
        "\n",
        "class SqlQuery:\n",
        "  def __init__(self, source_table, column_names, sink_table):\n",
        "    self.source_table = source_table\n",
        "\n",
        "    # Define how many comlumns there are\n",
        "    self.column_numbers = len(column_names) \n",
        "\n",
        "    # Transform the list of column names into a comma-separated string with the names\n",
        "    self.column_names = ', '.join(column_names) \n",
        "    self.sink_table = sink_table\n",
        "\n",
        "  # The following function returns SELECT query using column names from the 'column_names' variable,\n",
        "  # transformed in the above function to be a comma-separated string\n",
        "  def extract_query(self):\n",
        "    return 'SELECT ' + self.column_names + ' FROM ' + self.source_table \n",
        "\n",
        "  def load_query(self):\n",
        "\n",
        "    # As many comma-separated question marks as there are columns\n",
        "    values_str = '?,' * self.column_numbers\n",
        "\n",
        "    # Delete the last comma\n",
        "    values_str = values_str[:-1] \n",
        "\n",
        "    # Return an INSERT statement, targeting 'sink_table' with values not yet defined (question marks\n",
        "    # are here placeholders for a later function)\n",
        "    return 'INSERT OR REPLACE INTO ' + self.sink_table + ' VALUES (' + values_str + ')'\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtEGoZc_PU5-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Copy the data from the source db into the target db\n",
        "# source_cxn - connection to the source db\n",
        "# target_cnx - connection to the target db\n",
        "\n",
        "def etl(query, source_cnx, target_cnx):\n",
        "\n",
        "  ## extract data from source db\n",
        "  # create a cursor on the source connection\n",
        "  source_cursor = source_cnx.cursor()\n",
        "\n",
        "  # Using the query from the 'query' variable, it being a SqlQuery class object,\n",
        "  # use the 'extract_query' method to return a SELECT statement and then execute it\n",
        "  source_cursor.execute(query.extract_query())\n",
        "\n",
        "  # Store the extracted data in the 'data' variable\n",
        "  data = source_cursor.fetchall()\n",
        "\n",
        "  # close the cursor\n",
        "  source_cursor.close()\n",
        "\n",
        "\n",
        "  # load data into warehouse db\n",
        "  # if the data variable contains any data, do the following\n",
        "  if data:\n",
        "\n",
        "    # Initialize cursor on the target db connection\n",
        "    target_cursor = target_cnx.cursor()\n",
        "\n",
        "    # Using the 'load_query' method, return a Sql INSERT Statement and complement it with\n",
        "    # the data from the 'data' variable - that is the data extracted from the source table.\n",
        "    # Then, execute the statement using the target db cursor\n",
        "    target_cursor.executemany(query.load_query(), data)\n",
        "\n",
        "    # After executing the above statement, print out the following message\n",
        "    print('data loaded to warehouse db') \n",
        "\n",
        "    # Commit the changes to the targed db\n",
        "    target_cnx.commit()\n",
        "\n",
        "    # Close the cursor\n",
        "    target_cursor.close()\n",
        "  else:\n",
        "    print('data is empty')\n",
        "\n",
        "\n",
        "# Define a function to process multiple queries, so that the whole db can be copied\n",
        "\n",
        "def etl_process(queries, target_cnx, db_source):\n",
        "\n",
        "# 'queries' - a list of queries\n",
        "# 'target_cnx' - connection to the target DB\n",
        "# 'db_source' - path to the source db file\n",
        "\n",
        "  # establish source db connection\n",
        "  try:\n",
        "    source_cnx = sqlite3.connect(db_source)\n",
        "  except Error as err:\n",
        "    print(err)\n",
        "  \n",
        "  # loop through sql queries, using the above defined 'etl' function\n",
        "  for query in etl_queue:\n",
        "    etl(query, source_cnx, target_cnx)\n",
        "    \n",
        "  # close the source db connection\n",
        "  source_cnx.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB8GrFuLGRWb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## create Datawarehouse\n",
        "# Using the aforedefined DB Class, create a Database file in the 'DB_DWH_PATH' path\n",
        "# store it in a variable dwh_db\n",
        "dwh_db = DB(DB_DWH_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc28YPjOOpb0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Create sql queries to populate the tables\n",
        "\n",
        "# create an empty list, where later on the sql queries will be stored\n",
        "etl_queue = []\n",
        "\n",
        "# store the column names of the 'patients' table in a variable\n",
        "patients_columns = ['Id', 'BIRTHDATE', 'DEATHDATE', 'RACE', 'ETHNICITY']\n",
        "                  \n",
        "# create a variable sql_query_patients, which is to be of class 'SqlQuery'\n",
        "# the argument order within the class is: source_table, column_names, sink_table                \n",
        "sql_query_patients = SqlQuery(\"patients\", patients_columns, \"patients_info\")\n",
        "\n",
        "# add the above sql query to the query list\n",
        "etl_queue.append(sql_query_patients)\n",
        "\n",
        "\n",
        "# repeat the above process for the 'conditions' table\n",
        "conditions_columns = ['START', 'STOP', 'PATIENT', 'CODE']\n",
        "sql_query_conditions = SqlQuery(\"conditions\", conditions_columns, \"conditions_info\")\n",
        "etl_queue.append(sql_query_conditions)\n",
        "\n",
        "# repeat for the medications table\n",
        "medications_columns = ['START', 'STOP', 'PATIENT', 'CODE']\n",
        "sql_query_medications = SqlQuery(\"medications\", medications_columns, \"medications_info\")\n",
        "etl_queue.append(sql_query_medications)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzLfaWkfo3iC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# establish connection for target database\n",
        "target_cnx = dwh_db.conn\n",
        "\n",
        "# use the 'etl_process' function to fill the target database with the data from the source database\n",
        "# for every table, a message will be printed out\n",
        "etl_process(etl_queue, target_cnx, DB_SOURCE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB9oD761EGQx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "target_cnx.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RCROkRXNexD",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# check list of tables\n",
        "# there should be 2 tables: 'patients_info' and 'conditions_info'\n",
        "dwh_cursor = target_cnx.cursor()\n",
        "dwh_cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "print(dwh_cursor.fetchall())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhr0zUjHokFs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# now, populate the med_codes and the conditions_codes and group by code to get unique codes and their descriptions\n",
        "# to do that, use the data from the source database\n",
        "\n",
        "target_cnx = dwh_db.conn\n",
        "source_cnx = sqlite3.connect(DB_SOURCE_PATH)\n",
        "\n",
        "dwh_cursor = target_cnx.cursor()\n",
        "src_cursor = source_cnx.cursor()\n",
        "\n",
        "# table med_codes\n",
        "src_cursor.execute('''SELECT CODE, DESCRIPTION FROM medications GROUP BY CODE''')\n",
        "data = src_cursor.fetchall()\n",
        "dwh_cursor.executemany('''INSERT INTO med_codes (CODE, DESCRIPTION) VALUES (?,?)''', data)\n",
        "\n",
        "#table conditions_codes\n",
        "src_cursor.execute('''SELECT CODE, DESCRIPTION FROM conditions GROUP BY CODE''')\n",
        "data = src_cursor.fetchall()\n",
        "dwh_cursor.executemany('''INSERT INTO conditions_codes (CODE, DESCRIPTION) VALUES (?,?)''', data)\n",
        "\n",
        "\n",
        "#check if tables are properly populated\n",
        "dwh_cursor.execute('SELECT * FROM conditions_codes')\n",
        "data = dwh_cursor.fetchall()\n",
        "for n in data:\n",
        "  print(n)\n",
        "\n",
        "dwh_cursor.execute('SELECT * FROM med_codes')\n",
        "data = dwh_cursor.fetchall()\n",
        "for n in data:\n",
        "  print(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVFM9rOhwSoe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "target_cnx.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqkGj0mDK_V1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# check columns in a table\n",
        "dwh_cursor.execute('PRAGMA table_info(' + \"patients_info\" + ');')\n",
        "dwh_cursor.fetchall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rvpq5QEYfZmJ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# check if the table patients_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT * from patients_info limit 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1G-fY9FiSBU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# check if the table conditions_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT * from conditions_info LIMIT 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE-KTmZbqqyf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# check if the table encounters_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT * from medications_info LIMIT 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm9wlvJVd2CZ"
      },
      "source": [
        "## Pseudonymize the patients' Ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsQ53nZVz6ik"
      },
      "source": [
        "### Random string\n",
        "Define a function to generate random strings of a specified length in order to generate new Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "kM5MwJBlz6il"
      },
      "outputs": [],
      "source": [
        "def ranstr(length):\n",
        "    randomsigns = string.ascii_letters + string.digits\n",
        "    randomstring = ''.join(random.choice(randomsigns) for i in range(length))\n",
        "    return randomstring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1A82s2qz6il"
      },
      "source": [
        "### Fake Ids\n",
        "1. Generate the new Ids and stash them in a dictionary\n",
        "2. Create a new table that will be used to store the pseudonymized and original IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izHtf-ZRWg-i",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Fetch the original IDs from the patients_info table and store them in a variable Id_true.\n",
        "# Those are, by definition, all the original IDs that need to be pseudonymized\n",
        "dwh_cursor.execute('''SELECT Id FROM patients_info;''')\n",
        "Id_true = dwh_cursor.fetchall()\n",
        "\n",
        "# Id_true is now a list of tuples. In order to make it easier to loop over, convert it\n",
        "# into a list. Use a temporary variable tempid, loop over elements in the Id_true list\n",
        "# and choose the value indexed as 0. In the end, free the tempid variable\n",
        "tempid = [Id_true[n][0] for n in range(len(Id_true))]\n",
        "Id_true = tempid\n",
        "del tempid\n",
        "\n",
        "# Create an empty list to store pseudonymized IDs in.\n",
        "Id_fake = []\n",
        "\n",
        "# Populate the Id_fake list with random strings. The number of the random strings must be\n",
        "# the same as the number of the original IDs\n",
        "for n in range(len(Id_true)):\n",
        "    x = ranstr(20)\n",
        "\n",
        "    # if the above generated string is already in the list, generate consequent strings until\n",
        "    # nothing repeats itself\n",
        "    while x in Id_fake:\n",
        "      x = ranstr(20)\n",
        "    Id_fake.append(x)\n",
        "\n",
        "# Check if the lists are of the same length\n",
        "if len(Id_fake) != len(Id_true):\n",
        "  print('The lists contain different number of Ids')\n",
        "\n",
        "# Create a list of lists (an iterable of iterables) with the original and new IDs\n",
        "# to feed into the executemany function\n",
        "pseudo_data = [[Id_true[n], Id_fake[n]] for n in range(len(Id_fake))]\n",
        "\n",
        "\n",
        "# Create a dictionary with the original and new IDs to ease the process of \n",
        "# finding the corresponding ID (original and new)\n",
        "pseudo_dict = {pseudo_data[n][0] : pseudo_data[n][1] for n in range(len(pseudo_data))}\n",
        "\n",
        "# free the variables\n",
        "del pseudo_data\n",
        "del Id_fake\n",
        "del Id_true\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE TABLE WITH PSEUDO IDS\n",
        "\n",
        "# First, drop the table with the pseudonymized and original IDs, if exists\n",
        "# dwh_cursor.execute('''DROP TABLE IF EXISTS pseudo;''')\n",
        "\n",
        "# Create the table with the pseudonymized and original IDs\n",
        "# dwh_cursor.execute('''CREATE TABLE pseudo (Id, new_Id);''')\n",
        "\n",
        "# populate the 'pseudo' table with the original IDs and their corresponding pseudonymized counterparts\n",
        "# dwh_cursor.executemany('''INSERT OR REPLACE INTO pseudo (Id, new_Id) VALUES (?,?);''', pseudo_data)"
      ],
      "metadata": {
        "id": "emVP1FBtYTry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export the dictionary\n",
        "Save the dictionary to a csv file, so that, if need be, the patients' identity can be recovered."
      ],
      "metadata": {
        "id": "Mf09ZVj8PCbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV file path\n",
        "pseudo_csv_file = \"/content/drive/Shareddrives/TeamC/pseudo_data.csv\"\n",
        "\n",
        "# determine the names of the columns in the dictionary\n",
        "#pseudo_data_columns = ['original_ID', 'fake_ID']\n",
        "\n",
        "with open(pseudo_csv_file, mode = 'w', newline = '') as file:\n",
        "\n",
        "  #create a writer object\n",
        "  writer = csv.writer(file)\n",
        "\n",
        "  # write the values and keys of the ditionary to the csv file\n",
        "  writer.writerow(pseudo_dict.keys())\n",
        "  writer.writerow(pseudo_dict.values())"
      ],
      "metadata": {
        "id": "0-t8AtVpPaTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOo74Izjz6il"
      },
      "source": [
        "### Pseudonymize function\n",
        "Define a function that accepts the name of the table and column to be pseudonymized as well as a dictionary as a reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUOJb4pvWeqE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def pseudonymize(table, column, fake_dict):\n",
        "\n",
        "  # fetch the IDs from the selected table and store them in the variable 'table_data'\n",
        "  dwh_cursor.execute(f'''SELECT {column} FROM {table}''')\n",
        "  table_data = dwh_cursor.fetchall()\n",
        "  \n",
        "  # create two empty lists to store the original and pseudonymized IDs\n",
        "  orig_ids = []\n",
        "  fake_ids = []\n",
        "  \n",
        "  # populate the 'orig_ids' with the original IDs from the chosen table\n",
        "  orig_ids = [[table_data[n][0]] for n in range(len(table_data))]\n",
        "\n",
        "  # populate the 'fake_ids' with the pseudonymized IDs in the same order corresponding to the orig_ids\n",
        "  fake_ids = [[pseudo_dict[orig_ids[n][0]]] for n in range(len(orig_ids))]\n",
        "\n",
        "  # loop over every original id in the orig_ids and store it in the 'org' variable. Store its counterpart\n",
        "  # in the 'fake' variable. Then, use the sql REPLACE command to replace the original ID with the fake one.\n",
        "  for n in range(len(orig_ids)):\n",
        "    org = str(orig_ids[n][0])\n",
        "    fake = fake_ids[n][0]\n",
        "    try:\n",
        "      dwh_cursor.execute(f'''UPDATE {table} SET {column} = REPLACE({column}, ?, ?);''', (org, fake) )\n",
        "    except Error as err:\n",
        "      print(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0zxU3Uyz6il"
      },
      "source": [
        "### Run the pseudonymize function over the tables that need to be pseudonymized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3DD72NzWoku",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "pseudonymize('patients_info', 'Id', pseudo_dict)\n",
        "pseudonymize('conditions_info', 'PATIENT', pseudo_dict)\n",
        "pseudonymize('medications_info', 'PATIENT', pseudo_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLyq7HHMd-Pm"
      },
      "source": [
        "## Commit and close the connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-0dOoppGsyc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "target_cnx.commit()\n",
        "target_cnx.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}