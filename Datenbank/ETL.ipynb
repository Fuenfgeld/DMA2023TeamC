{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/DMA2023TeamC/blob/main/Datenbank/ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDF6jnIrk5L8"
      },
      "source": [
        "# **Objective**: Create a Datawarehouse and transform data from source database to datawarehouse db\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFINDtv7IOsW"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAtASFg0NjWe"
      },
      "source": [
        "import sqlite3\n",
        "from sqlite3 import Error"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5SVaUDA3QRc",
        "outputId": "7d041231-6e0b-4268-d955-8b19c79f877e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mount google Drive to access the data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "print(f'The current working directory is:')\n",
        "!pwd"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "The current working directory is:\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO-KOV0IITRx"
      },
      "source": [
        "# Path of input/output data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbN89u5p-vgO"
      },
      "source": [
        "# Define the variables to store the paths to csv files and to the data folder\n",
        "\n",
        "disease = 'metabolic_syndrome_disease'\n",
        "path_csv_files = f\"/content/drive/Shareddrives/TeamC/Material/csv_data/{disease}\"\n",
        "path_teamc = \"content/drive/Shareddrives/TeamC\"\n",
        "\n",
        "# path of the source database\n",
        "DB_SOURCE_PATH = \"/content/drive/Shareddrives/TeamC/teamc_db.db\"\n",
        "\n",
        "# path of the data warehouse\n",
        "DB_DWH_PATH = \"/content/drive/Shareddrives/TeamC/teamc_dwh.db\""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzL1jGs-751J"
      },
      "source": [
        "# Define the patient type\n",
        "patient_type = \"metabolic_syndrome_disease\"\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_WekES-IlMO"
      },
      "source": [
        "# Create Datawarehouse "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SL03VkYnodn"
      },
      "source": [
        "class DB(object):\n",
        "  def __init__(self, db_file):\n",
        "    self.conn = sqlite3.connect(db_file)\n",
        "    self.cur = self.conn.cursor()\n",
        "    self.__init_db()\n",
        "  \n",
        "  # This function commits the changes and closes the connection\n",
        "  def __del__(self):\n",
        "      self.conn.commit()\n",
        "      self.conn.close()\n",
        "\n",
        "  # If the DB does not exist, it will be created. Afterwards empty tables will be created using the SQL Statements from the source DB\n",
        "  def __init_db(self):\n",
        "\n",
        "    # drop the existing tables (in case the code has been run already)\n",
        "    drop_patients_info = \"\"\"DROP TABLE IF EXISTS patients_info\"\"\"\n",
        "    drop_conditions_info = \"\"\"DROP TABLE IF EXISTS conditions_info\"\"\"\n",
        "    drop_medications_info = \"\"\"DROP TABLE IF EXISTS medications_info\"\"\"\n",
        "    drop_med_codes = \"\"\"DROP TABLE IF EXISTS med_codes\"\"\"\n",
        "    drop_conditions_codes = \"\"\"DROP TABLE IF EXISTS conditions_codes\"\"\"\n",
        "\n",
        "    #  sql query to create patients_info table\n",
        "    create_patients_info = \"\"\"CREATE TABLE IF NOT EXISTS patients_info (\n",
        "                            Id STRING PRIMARY KEY, \n",
        "                            BIRTHDATE DATE, \n",
        "                            DEATHDATE DATE,\n",
        "                            RACE STRING,\n",
        "                            ETHNICITY STRING\n",
        "                            );\"\"\"\n",
        "\n",
        "\n",
        "    # sql query to create conditions table\n",
        "    create_conditions_info = \"\"\"CREATE TABLE IF NOT EXISTS conditions_info (\n",
        "                                START DATE,\n",
        "                                STOP DATE, \n",
        "                                PATIENT STRING,\n",
        "                                CODE STRING,\n",
        "                                FOREIGN KEY (PATIENT) REFERENCES patients_info (Id)\n",
        "                                FOREIGN KEY (CODE) REFERENCES conditions_codes (CODE)\n",
        "                                );\"\"\"\n",
        "\n",
        "    # sql query to create medications table\n",
        "    create_medications_info = '''CREATE TABLE IF NOT EXISTS medications_info (\n",
        "                                  START DATE,\n",
        "                                  STOP DATE,\n",
        "                                  PATIENT STRING,\n",
        "                                  CODE STRING,\n",
        "                                  FOREIGN KEY (PATIENT) REFERENCES patients (Id)\n",
        "                                  FOREIGN KEY (CODE) REFERENCES med_codes (CODE)\n",
        "                                  );'''\n",
        "    # create table to store the medication codes and their description\n",
        "    create_med_codes = '''CREATE TABLE IF NOT EXISTS med_codes (\n",
        "                          CODE STRING,\n",
        "                          DESCRIPTION STRING);'''\n",
        "                          \n",
        "    # create table to store conditions codes and their description\n",
        "    create_conditions_codes = '''CREATE TABLE IF NOT EXISTS conditions_codes (\n",
        "                              CODE STRING,\n",
        "                              DESCRIPTION STRING);'''                   \n",
        "\n",
        "\n",
        "    # A list with the names of the tables that were created in the new DB\n",
        "    create_tables = [create_patients_info, # demographic data\n",
        "                     create_conditions_info, # diagnoses data\n",
        "                     create_medications_info,# encounters data\n",
        "                     create_med_codes, # medication codes and their description\n",
        "                     create_conditions_codes #condition codes and their description\n",
        "                     ]\n",
        "    drop_tables =  [drop_patients_info,\n",
        "                   drop_conditions_info,\n",
        "                   drop_medications_info,\n",
        "                   drop_med_codes,\n",
        "                   drop_conditions_codes]\n",
        "\n",
        "    if self.conn is not None: # If connection was succesfully initialized, the following loop will run\n",
        "      \n",
        "      # Drop every table\n",
        "      for query in drop_tables:\n",
        "        self.cur.execute(query)\n",
        "        \n",
        "      # For every element in the 'create_tables' list, its corresponding statement will be executed, \n",
        "      # which in this case means, the creating of the tables\n",
        "      for query in create_tables:\n",
        "        self.cur.execute(query)\n",
        "\n",
        "    else:\n",
        "      # If the connection was not succesfully initialized, print this message\n",
        "      print('Connection to database failed')\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUIHYzr2IxMl"
      },
      "source": [
        "#ETL/ELT (Extract, transform, load )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBMOAjmPReGG"
      },
      "source": [
        "# Defining class SqlQuery and its methods\n",
        "\n",
        "class SqlQuery:\n",
        "  def __init__(self, source_table, column_names, sink_table):\n",
        "    self.source_table = source_table\n",
        "\n",
        "    # Define how many comlumns there are\n",
        "    self.column_numbers = len(column_names) \n",
        "\n",
        "    # Transform the list of column names into a comma-separated string with the names\n",
        "    self.column_names = ', '.join(column_names) \n",
        "    self.sink_table = sink_table\n",
        "\n",
        "  # The following function returns SELECT query using column names from the 'column_names' variable,\n",
        "  # transformed in the above function to be a comma-separated string\n",
        "  def extract_query(self):\n",
        "    return 'SELECT ' + self.column_names + ' FROM ' + self.source_table \n",
        "\n",
        "  def load_query(self):\n",
        "\n",
        "    # As many comma-separated question marks as there are columns\n",
        "    values_str = '?,' * self.column_numbers\n",
        "\n",
        "    # Delete the last comma\n",
        "    values_str = values_str[:-1] \n",
        "\n",
        "    # Return an INSERT statement, targeting 'sink_table' with values not yet defined (question marks\n",
        "    # are here placeholders for a later function)\n",
        "    return 'INSERT OR REPLACE INTO ' + self.sink_table + ' VALUES (' + values_str + ')'\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtEGoZc_PU5-"
      },
      "source": [
        "# Copy the data from the source db into the target db\n",
        "# source_cxn - connection to the source db\n",
        "# target_cnx - connection to the target db\n",
        "\n",
        "def etl(query, source_cnx, target_cnx):\n",
        "\n",
        "  ## extract data from source db\n",
        "  # create a cursor on the source connection\n",
        "  source_cursor = source_cnx.cursor()\n",
        "\n",
        "  # Using the query from the 'query' variable, it being a SqlQuery class object,\n",
        "  # use the 'extract_query' method to return a SELECT statement and then execute it\n",
        "  source_cursor.execute(query.extract_query())\n",
        "\n",
        "  # Store the extracted data in the 'data' variable\n",
        "  data = source_cursor.fetchall()\n",
        "\n",
        "  # close the cursor\n",
        "  source_cursor.close()\n",
        "\n",
        "\n",
        "  # load data into warehouse db\n",
        "  # if the data variable contains any data, do the following\n",
        "  if data:\n",
        "\n",
        "    # Initialize cursor on the target db connection\n",
        "    target_cursor = target_cnx.cursor()\n",
        "\n",
        "    # Using the 'load_query' method, return a Sql INSERT Statement and complement it with\n",
        "    # the data from the 'data' variable - that is the data extracted from the source table.\n",
        "    # Then, execute the statement using the target db cursor\n",
        "    target_cursor.executemany(query.load_query(), data)\n",
        "\n",
        "    # After executing the above statement, print out the following message\n",
        "    print('data loaded to warehouse db') \n",
        "\n",
        "    # Commit the changes to the targed db\n",
        "    target_cnx.commit()\n",
        "\n",
        "    # Close the cursor\n",
        "    target_cursor.close()\n",
        "  else:\n",
        "    print('data is empty')\n",
        "\n",
        "\n",
        "# Define a function to process multiple queries, so that the whole db can be copied\n",
        "\n",
        "def etl_process(queries, target_cnx, db_source):\n",
        "\n",
        "# 'queries' - a list of queries\n",
        "# 'target_cnx' - connection to the target DB\n",
        "# 'db_source' - path to the source db file\n",
        "\n",
        "  # establish source db connection\n",
        "  try:\n",
        "    source_cnx = sqlite3.connect(db_source)\n",
        "  except Error as err:\n",
        "    print(err)\n",
        "  \n",
        "  # loop through sql queries, using the above defined 'etl' function\n",
        "  for query in etl_queue:\n",
        "    etl(query, source_cnx, target_cnx)\n",
        "    \n",
        "  # close the source db connection\n",
        "  source_cnx.close()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB8GrFuLGRWb"
      },
      "source": [
        "## create Datawarehouse\n",
        "# Using the aforedefined DB Class, create a Database file in the 'DB_DWH_PATH' path\n",
        "# store it in a variable dwh_db\n",
        "dwh_db = DB(DB_DWH_PATH)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc28YPjOOpb0",
        "outputId": "f109fa72-a4c4-47d0-885c-392b1dcd58ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Create sql queries to populate the tables\n",
        "\n",
        "# create an empty list, where later on the sql queries will be stored\n",
        "etl_queue = []\n",
        "\n",
        "# store the column names of the 'patients' table in a variable\n",
        "patients_columns = ['Id', 'BIRTHDATE', 'DEATHDATE', 'RACE', 'ETHNICITY']\n",
        "                  \n",
        "# create a variable sql_query_patients, which is to be of class 'SqlQuery'\n",
        "# the argument order within the class is: source_table, column_names, sink_table                \n",
        "sql_query_patients = SqlQuery(\"patients\", patients_columns, \"patients_info\")\n",
        "\n",
        "# add the above sql query to the query list\n",
        "etl_queue.append(sql_query_patients)\n",
        "\n",
        "\n",
        "# repeat the above process for the 'conditions' table\n",
        "conditions_columns = ['START', 'STOP', 'PATIENT', 'CODE']\n",
        "sql_query_conditions = SqlQuery(\"conditions\", conditions_columns, \"conditions_info\")\n",
        "etl_queue.append(sql_query_conditions)\n",
        "\n",
        "# repeat for the medications table\n",
        "medications_columns = ['START', 'STOP', 'PATIENT', 'CODE']\n",
        "sql_query_medications = SqlQuery(\"medications\", medications_columns, \"medications_info\")\n",
        "etl_queue.append(sql_query_medications)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function DB.__del__ at 0x7f07db1885e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-57-4edb33b9f4ae>\", line 9, in __del__\n",
            "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139672820598592 and this is thread id 139672216528640.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzLfaWkfo3iC",
        "outputId": "d929e679-d50d-4324-e1c7-43d5e31b29fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# establish connection for target database\n",
        "target_cnx = dwh_db.conn\n",
        "\n",
        "# use the 'etl_process' function to fill the target database with the data from the source database\n",
        "# for every table, a message will be printed out\n",
        "etl_process(etl_queue, target_cnx, DB_SOURCE_PATH)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB9oD761EGQx"
      },
      "source": [
        "target_cnx.commit()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RCROkRXNexD",
        "outputId": "e9215502-525e-41a8-a7bd-69ad372b29b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check list of tables\n",
        "# there should be 2 tables: 'patients_info' and 'conditions_info'\n",
        "dwh_cursor = target_cnx.cursor()\n",
        "dwh_cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "print(dwh_cursor.fetchall())\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('patients_info',), ('conditions_info',), ('medications_info',), ('med_codes',), ('conditions_codes',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, populate the med_codes and the conditions_codes and group by code to get unique codes and their descriptions\n",
        "# to do that, use the data from the source database\n",
        "\n",
        "target_cnx = dwh_db.conn\n",
        "source_cnx = sqlite3.connect(DB_SOURCE_PATH)\n",
        "\n",
        "dwh_cursor = target_cnx.cursor()\n",
        "src_cursor = source_cnx.cursor()\n",
        "\n",
        "# table med_codes\n",
        "src_cursor.execute('''SELECT CODE, DESCRIPTION FROM medications GROUP BY CODE''')\n",
        "data = src_cursor.fetchall()\n",
        "dwh_cursor.executemany('''INSERT INTO med_codes (CODE, DESCRIPTION) VALUES (?,?)''', data)\n",
        "\n",
        "#table conditions_codes\n",
        "src_cursor.execute('''SELECT CODE, DESCRIPTION FROM conditions GROUP BY CODE''')\n",
        "data = src_cursor.fetchall()\n",
        "dwh_cursor.executemany('''INSERT INTO conditions_codes (CODE, DESCRIPTION) VALUES (?,?)''', data)\n",
        "\n",
        "\n",
        "#check if tables are properly populated\n",
        "dwh_cursor.execute('SELECT * FROM conditions_codes')\n",
        "data = dwh_cursor.fetchall()\n",
        "for n in data:\n",
        "  print(n)\n",
        "\n",
        "dwh_cursor.execute('SELECT * FROM med_codes')\n",
        "data = dwh_cursor.fetchall()\n",
        "for n in data:\n",
        "  print(n)"
      ],
      "metadata": {
        "id": "Zhr0zUjHokFs",
        "outputId": "61c6e744-67cd-4c36-f988-6920fc87da7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22298006, 'Myocardial Infarction')\n",
            "(49436004, 'Atrial Fibrillation')\n",
            "(53741008, 'Coronary Heart Disease')\n",
            "(230690007, 'Stroke')\n",
            "(399211009, 'History of myocardial infarction (situation)')\n",
            "(410429000, 'Cardiac Arrest')\n",
            "(429007001, 'History of cardiac arrest (situation)')\n",
            "(197361, 'Amlodipine 5 MG Oral Tablet')\n",
            "(197604, 'Digoxin 0.125 MG Oral Tablet')\n",
            "(259255, 'Atorvastatin 80 MG Oral Tablet')\n",
            "(309362, 'Clopidogrel 75 MG Oral Tablet')\n",
            "(312961, 'Simvastatin 20 MG Oral Tablet')\n",
            "(705129, 'Nitroglycerin 0.4 MG/ACTUAT Mucosal Spray')\n",
            "(833036, 'Captopril 25 MG Oral Tablet')\n",
            "(834357, '3 ML Amiodarone hydrocholoride 50 MG/ML Prefilled Syringe')\n",
            "(855332, 'Warfarin Sodium 5 MG Oral Tablet')\n",
            "(897718, 'Verapamil Hydrochloride 40 MG')\n",
            "(1190795, 'Atropine Sulfate 1 MG/ML Injectable Solution')\n",
            "(1660014, '1 ML Epinephrine 1 MG/ML Injection')\n",
            "(1804799, 'Alteplase 100 MG Injection')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_cnx.commit()"
      ],
      "metadata": {
        "id": "xVFM9rOhwSoe"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkGj0mDK_V1",
        "outputId": "f049efdc-fddf-457c-a40f-a416c98e447a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check columns in a table\n",
        "dwh_cursor.execute('PRAGMA table_info(' + \"patients_info\" + ');')\n",
        "dwh_cursor.fetchall()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'Id', 'STRING', 0, None, 1),\n",
              " (1, 'BIRTHDATE', 'DATE', 0, None, 0),\n",
              " (2, 'DEATHDATE', 'DATE', 0, None, 0),\n",
              " (3, 'RACE', 'STRING', 0, None, 0),\n",
              " (4, 'ETHNICITY', 'STRING', 0, None, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvpq5QEYfZmJ",
        "outputId": "700b9534-dd1c-4c9f-f538-cbf091cf2c5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check if the table patients_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT * from patients_info limit 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('5e96bd7f-bdc3-7787-110f-ba2dfb89948b', '1982-09-20', None, 'white', 'nonhispanic')\n",
            "('19a257c0-1425-cb43-c92b-60be60a62e4b', '2012-07-11', None, 'white', 'nonhispanic')\n",
            "('e864c897-cc30-45e3-0950-8503ed51d86c', '1997-07-22', None, 'white', 'hispanic')\n",
            "('1f162789-128f-2fa6-3c99-c4a517a7e694', '1994-12-07', None, 'white', 'nonhispanic')\n",
            "('0508d723-6462-c769-7050-e9eff1f61ec7', '1971-04-05', None, 'white', 'nonhispanic')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1G-fY9FiSBU",
        "outputId": "fff147b0-5e80-40d7-ff5d-a40a1634ae46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check if the table conditions_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT * from conditions_info LIMIT 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('2007-11-29', None, '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 53741008)\n",
            "('2011-06-09', None, '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 22298006)\n",
            "('2011-06-09', None, '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 399211009)\n",
            "('2016-08-25', None, '652d25f0-b857-88a9-0957-59566f1c389c', 410429000)\n",
            "('2016-08-25', None, '652d25f0-b857-88a9-0957-59566f1c389c', 429007001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the table encounters_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT * from medications_info LIMIT 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ],
      "metadata": {
        "id": "eE-KTmZbqqyf",
        "outputId": "ae904445-7924-478c-a62c-f87be7e50092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('2007-11-29T14:30:10Z', '2011-06-09T14:45:10Z', '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 309362)\n",
            "('2007-11-29T14:30:10Z', None, '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 312961)\n",
            "('2007-11-29T14:30:10Z', None, '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 197361)\n",
            "('2007-11-29T14:30:10Z', '2011-06-09T14:45:10Z', '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 705129)\n",
            "('2011-06-09T14:30:10Z', '2011-06-09T14:45:10Z', '0d04cd1b-3c01-0a2d-1f67-d7dd491149ad', 259255)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_cnx.close()"
      ],
      "metadata": {
        "id": "x-0dOoppGsyc"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}