{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/DMA2023TeamC/blob/main/Datenbank/ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDF6jnIrk5L8"
      },
      "source": [
        "# **Objective**: Create a Datawarehouse and transform data from source database to datawarehouse db\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFINDtv7IOsW"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAtASFg0NjWe"
      },
      "source": [
        "import sqlite3\n",
        "from sqlite3 import Error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5SVaUDA3QRc"
      },
      "source": [
        "# Mount google Drive to access the data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "print(f'The current working directory is:')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO-KOV0IITRx"
      },
      "source": [
        "# Path of input/output data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbN89u5p-vgO"
      },
      "source": [
        "# Define the variables to store the paths to csv files and to the data folder\n",
        "\n",
        "disease = 'metabolic_syndrome_disease'\n",
        "path_csv_files = f\"/content/drive/Shareddrives/TeamC/Material/csv_data/{disease}\"\n",
        "path_teamc = \"content/drive/Shareddrives/TeamC\"\n",
        "\n",
        "# path of the source database\n",
        "DB_SOURCE_PATH = \"/content/drive/Shareddrives/TeamC/teamc_db.db\"\n",
        "\n",
        "# path of the data warehouse\n",
        "DB_DWH_PATH = \"/content/drive/Shareddrives/TeamC/teamc_dwh.db\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzL1jGs-751J"
      },
      "source": [
        "# Define the patient type\n",
        "patient_type = \"metabolic_syndrome_disease\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_WekES-IlMO"
      },
      "source": [
        "# Create Datawarehouse "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SL03VkYnodn"
      },
      "source": [
        "class DB(object):\n",
        "  def __init__(self, db_file):\n",
        "    self.conn = sqlite3.connect(db_file)\n",
        "    self.cur = self.conn.cursor()\n",
        "    self.__init_db()\n",
        "  \n",
        "  # This function commits the changes and closes the connection\n",
        "  def __del__(self):\n",
        "      self.conn.commit()\n",
        "      self.conn.close()\n",
        "\n",
        "  # If the DB does not exist, it will be created. Afterwards empty tables will be created using the SQL Statements from the source DB\n",
        "  def __init_db(self):\n",
        "\n",
        "    #  sql query to create patients_info table\n",
        "    create_patients_info = \"\"\"CREATE TABLE IF NOT EXISTS patients_info (\n",
        "                            Id STRING PRIMARY KEY, \n",
        "                            BIRTHDATE DATE, \n",
        "                            DEATHDATE DATE,\n",
        "                            SSN STRING,\n",
        "                            DRIVERS STRING,\n",
        "                            PASSPORT STRING,\n",
        "                            PREFIX STRING,\n",
        "                            FIRST STRING,\n",
        "                            LAST STRING,\n",
        "                            SUFFIX STRING,\n",
        "                            MAIDEN STRING,\n",
        "                            MARITAL STRING,\n",
        "                            RACE STRING,\n",
        "                            ETHNICITY STRING,\n",
        "                            GENDER STRING,\n",
        "                            BIRTHPLACE STRING,\n",
        "                            ADDRESS STRING,\n",
        "                            CITY STRING,\n",
        "                            STATE STRING,\n",
        "                            COUNTY STRING,\n",
        "                            ZIP STRING,\n",
        "                            LAT STRING,\n",
        "                            LON STRING,\n",
        "                            HEALTHCARE_EXPENSES INTEGER,\n",
        "                            HEALTHCARE_COVERAGE INTEGER\n",
        "                            );\"\"\"\n",
        "\n",
        "\n",
        "    # sql query to create conditions table\n",
        "    create_conditions_info = \"\"\"CREATE TABLE IF NOT EXISTS conditions_info (\n",
        "                                START DATE,\n",
        "                                STOP DATE, \n",
        "                                PATIENT STRING,\n",
        "                                ENCOUNTER STRING,\n",
        "                                CODE STRING,\n",
        "                                DESCRIPTION STRING,\n",
        "                                FOREIGN KEY (PATIENT) REFERENCES patients (Id)\n",
        "                                FOREIGN KEY (ENCOUNTER) REFERENCES encounters (Id)\n",
        "                              )\"\"\"\n",
        "\n",
        "    # A list with the names of the tables that were created in the new DB\n",
        "    create_tables = [create_patients_info, # demographic data\n",
        "                     create_conditions_info, # diagnoses data\n",
        "                     ]\n",
        "     \n",
        "\n",
        "    if self.conn is not None: # If connection was succesfully initialized, the following loop will run\n",
        "      \n",
        "      # For every element in the 'create_tables' list, its corresponding statement will be executed, \n",
        "      # which in this case means, the creating of the tables\n",
        "      for query in create_tables:\n",
        "          self.cur.execute(query)\n",
        "    else:\n",
        "      # If the connection was not succesfully initialized, print this message\n",
        "      print('Connection to database failed')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUIHYzr2IxMl"
      },
      "source": [
        "#ETL/ELT (Extract, transform, load )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBMOAjmPReGG"
      },
      "source": [
        "# Defining class SqlQuery and its methods\n",
        "\n",
        "class SqlQuery:\n",
        "  def __init__(self, source_table, column_names, sink_table):\n",
        "    self.source_table = source_table\n",
        "\n",
        "    # Define how many comlumns there are\n",
        "    self.column_numbers = len(column_names) \n",
        "\n",
        "    # Transform the list of column names into a comma-separated string with the names\n",
        "    self.column_names = ', '.join(column_names) \n",
        "    self.sink_table = sink_table\n",
        "\n",
        "  # The following function returns SELECT query using column names from the 'column_names' variable,\n",
        "  # transformed in the above function to be a comma-separated string\n",
        "  def extract_query(self):\n",
        "    return 'SELECT ' + self.column_names + ' FROM ' + self.source_table \n",
        "\n",
        "  def load_query(self):\n",
        "\n",
        "    # As many comma-separated question marks as there are columns\n",
        "    values_str = '?,' * self.column_numbers\n",
        "\n",
        "    # Delete the last comma\n",
        "    values_str = values_str[:-1] \n",
        "\n",
        "    # Return an INSERT statement, targeting 'sink_table' with values not yet defined (question marks\n",
        "    # are here placeholders for a later function)\n",
        "    return 'INSERT OR REPLACE INTO ' + self.sink_table + ' VALUES (' + values_str + ')'\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtEGoZc_PU5-"
      },
      "source": [
        "# Copy the data from the source db into the target db\n",
        "# source_cxn - connection to the source db\n",
        "# target_cnx - connection to the target db\n",
        "\n",
        "def etl(query, source_cnx, target_cnx):\n",
        "\n",
        "  ## extract data from source db\n",
        "  # create a cursor on the source connection\n",
        "  source_cursor = source_cnx.cursor()\n",
        "\n",
        "  # Using the query from the 'query' variable, it being a SqlQuery class object,\n",
        "  # use the 'extract_query' method to return a SELECT statement and then execute it\n",
        "  source_cursor.execute(query.extract_query())\n",
        "\n",
        "  # Store the extracted data in the 'data' variable\n",
        "  data = source_cursor.fetchall()\n",
        "\n",
        "  # close the cursor\n",
        "  source_cursor.close()\n",
        "\n",
        "\n",
        "  # load data into warehouse db\n",
        "  # if the data variable contains any data, do the following\n",
        "  if data:\n",
        "\n",
        "    # Initialize cursor on the target db connection\n",
        "    target_cursor = target_cnx.cursor()\n",
        "\n",
        "    # Using the 'load_query' method, return a Sql INSERT Statement and complement it with\n",
        "    # the data from the 'data' variable - that is the data extracted from the source table.\n",
        "    # Then, execute the statement using the target db cursor\n",
        "    target_cursor.executemany(query.load_query(), data)\n",
        "\n",
        "    # After executing the above statement, print out the following message\n",
        "    print('data loaded to warehouse db') \n",
        "\n",
        "    # Commit the changes to the targed db\n",
        "    target_cnx.commit()\n",
        "\n",
        "    # Close the cursor\n",
        "    target_cursor.close()\n",
        "  else:\n",
        "    print('data is empty')\n",
        "\n",
        "\n",
        "# Define a function to process multiple queries, so that the whole db can be copied\n",
        "\n",
        "def etl_process(queries, target_cnx, db_source):\n",
        "\n",
        "# 'queries' - a list of queries\n",
        "# 'target_cnx' - connection to the target DB\n",
        "# 'db_source' - path to the source db file\n",
        "\n",
        "  # establish source db connection\n",
        "  try:\n",
        "    source_cnx = sqlite3.connect(db_source)\n",
        "  except Error as err:\n",
        "    print(err)\n",
        "  \n",
        "  # loop through sql queries, using the above defined 'etl' function\n",
        "  for query in etl_queue:\n",
        "    etl(query, source_cnx, target_cnx)\n",
        "    \n",
        "  # close the source db connection\n",
        "  source_cnx.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB8GrFuLGRWb"
      },
      "source": [
        "## create Datawarehouse\n",
        "# Using the aforedefined DB Class, create a Database file in the 'DB_DWH_PATH' path\n",
        "# store it in a variable dwh_db\n",
        "dwh_db = DB(DB_DWH_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc28YPjOOpb0"
      },
      "source": [
        "print('starting etl')   \n",
        "# create an empty list, where later on the sql queries will be stored\n",
        "etl_queue = []\n",
        "\n",
        "# store the column names of the 'patients' table in a variable\n",
        "patients_columns = ['Id', 'BIRTHDATE', 'DEATHDATE', 'SSN', 'DRIVERS', 'PASSPORT', 'PREFIX',\n",
        "                    'FIRST', 'LAST', 'SUFFIX', 'MAIDEN', 'MARITAL', 'RACE', 'ETHNICITY',\n",
        "                    'GENDER', 'BIRTHPLACE', 'ADDRESS', 'CITY', 'STATE', 'COUNTY', 'ZIP',\n",
        "                    'LAT', 'LON', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE']\n",
        "                  \n",
        "# create a variable sql_query_patients, which is to be of class 'SqlQuery'\n",
        "# the argument order within the class is: source_table, column_names, sink_table                \n",
        "sql_query_patients = SqlQuery(\"patients\", patients_columns, \"patients_info\")\n",
        "\n",
        "# add the above sql query to the query list\n",
        "etl_queue.append(sql_query_patients)\n",
        "\n",
        "\n",
        "# repeat the above process for the 'conditions' table\n",
        "conditions_columns = ['START', 'STOP', 'PATIENT', 'ENCOUNTER', 'CODE', 'DESCRIPTION']\n",
        "sql_query_conditions = SqlQuery(\"conditions\", conditions_columns, \"conditions_info\")\n",
        "etl_queue.append(sql_query_conditions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzLfaWkfo3iC"
      },
      "source": [
        "# establish connection for target database\n",
        "target_cnx = dwh_db.conn\n",
        "\n",
        "# use the 'etl_process' function to fill the target database with the data from the source database\n",
        "# for every table, a message will be printed out\n",
        "etl_process(etl_queue, target_cnx, DB_SOURCE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB9oD761EGQx"
      },
      "source": [
        "target_cnx.commit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RCROkRXNexD"
      },
      "source": [
        "# check list of tables\n",
        "# there should be 2 tables: 'patients_info' and 'conditions_info'\n",
        "dwh_cursor = target_cnx.cursor()\n",
        "dwh_cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "print(dwh_cursor.fetchall())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkGj0mDK_V1"
      },
      "source": [
        "# check columns in a table\n",
        "dwh_cursor.execute('PRAGMA table_info(' + \"patients_info\" + ');')\n",
        "dwh_cursor.fetchall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvpq5QEYfZmJ"
      },
      "source": [
        "# check if the table patients_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT Id, BIRTHDATE, FIRST, LAST, MARITAL, GENDER from patients_info limit 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1G-fY9FiSBU"
      },
      "source": [
        "# check if the table patients_info is properly filled by printing out the first 5 rows\n",
        "dwh_cursor.execute(\"SELECT START, PATIENT,CODE, DESCRIPTION from conditions_info LIMIT 5\")\n",
        "rows = dwh_cursor.fetchall()\n",
        "for row in rows:\n",
        "  print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cnx.close()"
      ],
      "metadata": {
        "id": "x-0dOoppGsyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-DLW9DWzDJ2"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}